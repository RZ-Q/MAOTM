# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 50000    # 50000   1000000

runner: "episode"
batch_size_run: 1 # Number of environments to run in parallel

buffer_size: 5000

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "mbom_learner"
double_q: True
mixer: "qmix"     # vdn  qmix
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

mac: "mbom_mac"
agent: "mbom"

name: "mbom"

#######
hidden_dim: 64   # Size of hidden state for feature
n_rollout_steps: 3
lr_env: 0.001
query_dim: 32
key_dim: 32
mess_dim: 64
lamda_q: 1.0

